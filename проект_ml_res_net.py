# -*- coding: utf-8 -*-
"""проект_ML_Res_net.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oCW0W7eIFKh4LH_v4cLeR5qgt23OWY9S
"""

import os
import json
import zipfile
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Subset
from torchvision import datasets, transforms, models
from sklearn.metrics import confusion_matrix, classification_report
from tqdm import tqdm
from google.colab import drive
drive.mount('/content/drive')

ZIP_PATH_DRIVE = "/content/drive/MyDrive/Colab Notebooks/ad_and_mo/GTSRB_prepared.zip"
DATA_ROOT = "/content/GTSRB_prepared"

import shutil, zipfile, os

if os.path.exists(DATA_ROOT):
    shutil.rmtree(DATA_ROOT)

os.makedirs(DATA_ROOT, exist_ok=True)

with zipfile.ZipFile(ZIP_PATH_DRIVE, 'r') as zip_ref:
    zip_ref.extractall(DATA_ROOT)

!ls -R /content/GTSRB_prepared

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Используемое устройство: {device}")

SEED = 42
np.random.seed(SEED)
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed(SEED)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

DATA_PATH = DATA_ROOT
TRAIN_PATH = os.path.join(DATA_PATH, "Train")
PROCESSED_TEST_PATH = os.path.join(DATA_PATH, "ProcessedTest")
META_PATH = os.path.join(DATA_PATH, "split_meta")

RESULTS_DIR = "/content/resnet18_results"
os.makedirs(RESULTS_DIR, exist_ok=True)

def load_split_metadata(meta_path):
    with open(os.path.join(meta_path, 'train_indices.json'), 'r') as f:
        train_indices = json.load(f)
    with open(os.path.join(meta_path, 'val_indices.json'), 'r') as f:
        val_indices = json.load(f)
    with open(os.path.join(meta_path, 'test_indices.json'), 'r') as f:
        test_indices = json.load(f)
    with open(os.path.join(meta_path, 'class_to_idx.json'), 'r') as f:
        class_to_idx = json.load(f)
    return train_indices, val_indices, test_indices, class_to_idx

train_indices, val_indices, test_indices, class_to_idx = load_split_metadata(META_PATH)
print(f"Train: {len(train_indices)}, Val: {len(val_indices)}, Internal Test: {len(test_indices)}")
print(f"Количество классов: {len(class_to_idx)}")

idx_to_class = {v: k for k, v in class_to_idx.items()}
num_classes = len(class_to_idx)

IMG_SIZE = 224

IMAGENET_MEAN = [0.485, 0.456, 0.406]
IMAGENET_STD  = [0.229, 0.224, 0.225]

train_transform = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1),
    transforms.RandomAffine(degrees=5, translate=(0.02, 0.02), scale=(0.95, 1.05)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ToTensor(),
    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),
])

val_test_transform = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),
])

dataset_train_full = datasets.ImageFolder(root=TRAIN_PATH, transform=train_transform)
dataset_val_full   = datasets.ImageFolder(root=TRAIN_PATH, transform=val_test_transform)

train_dataset = Subset(dataset_train_full, train_indices)
val_dataset   = Subset(dataset_val_full,   val_indices)

print(f"Размер train_dataset: {len(train_dataset)}")
print(f"Размер val_dataset:   {len(val_dataset)}")

processed_test_dataset = datasets.ImageFolder(
    root=PROCESSED_TEST_PATH,
    transform=val_test_transform
)
print(f"Размер processed_test_dataset: {len(processed_test_dataset)}")
print(f"Число классов в ProcessedTest: {len(processed_test_dataset.classes)}")

BATCH_SIZE = 64
LR = 1e-3
WEIGHT_DECAY = 1e-4
NUM_EPOCHS = 20

train_loader = DataLoader(
    train_dataset,
    batch_size=BATCH_SIZE,
    shuffle=True,
    num_workers=2,
    pin_memory=True
)

val_loader = DataLoader(
    val_dataset,
    batch_size=BATCH_SIZE,
    shuffle=False,
    num_workers=2,
    pin_memory=True
)

final_test_loader = DataLoader(
    processed_test_dataset,
    batch_size=BATCH_SIZE,
    shuffle=False,
    num_workers=2,
    pin_memory=True
)
resnet18 = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
in_features = resnet18.fc.in_features
resnet18.fc = nn.Linear(in_features, num_classes)
resnet18 = resnet18.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(resnet18.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)

history = {
    "train_loss": [],
    "val_loss": [],
    "train_acc": [],
    "val_acc": [],
}

def train_one_epoch(model, loader, optimizer, criterion, device):
    model.train()
    running_loss = 0.0
    running_corrects = 0

    for inputs, labels in tqdm(loader, desc="Train", leave=False):
        inputs = inputs.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        _, preds = torch.max(outputs, 1)
        running_loss += loss.item() * inputs.size(0)
        running_corrects += torch.sum(preds == labels)

    epoch_loss = running_loss / len(loader.dataset)
    epoch_acc = running_corrects.double().item() / len(loader.dataset)
    return epoch_loss, epoch_acc


def evaluate(model, loader, criterion, device):
    model.eval()
    running_loss = 0.0
    running_corrects = 0

    with torch.no_grad():
        for inputs, labels in tqdm(loader, desc="Val/Test", leave=False):
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model(inputs)
            loss = criterion(outputs, labels)

            _, preds = torch.max(outputs, 1)
            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == labels)

    epoch_loss = running_loss / len(loader.dataset)
    epoch_acc = running_corrects.double().item() / len(loader.dataset)
    return epoch_loss, epoch_acc

best_val_acc = 0.0
best_model_state = None

for epoch in range(1, NUM_EPOCHS + 1):
    print(f"\nEpoch {epoch}/{NUM_EPOCHS}")

    train_loss, train_acc = train_one_epoch(resnet18, train_loader, optimizer, criterion, device)
    val_loss, val_acc = evaluate(resnet18, val_loader, criterion, device)

    scheduler.step()

    history["train_loss"].append(train_loss)
    history["val_loss"].append(val_loss)
    history["train_acc"].append(train_acc)
    history["val_acc"].append(val_acc)

    print(f"Train  Loss: {train_loss:.4f} | Acc: {train_acc:.4f}")
    print(f"Val    Loss: {val_loss:.4f} | Acc: {val_acc:.4f}")

    if val_acc > best_val_acc:
        best_val_acc = val_acc
        best_model_state = resnet18.state_dict().copy()

print(f"\nЛучшее val accuracy: {best_val_acc:.4f}")

if best_model_state is not None:
    resnet18.load_state_dict(best_model_state)

model_path = os.path.join(RESULTS_DIR, "model_resnet18.pth")
torch.save(resnet18.state_dict(), model_path)
print(f"Модель сохранена в: {model_path}")

epochs = range(1, NUM_EPOCHS + 1)

plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
plt.plot(epochs, history["train_loss"], label="Train loss")
plt.plot(epochs, history["val_loss"], label="Val loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.title("ResNet18 – Loss")

plt.subplot(1, 2, 2)
plt.plot(epochs, history["train_acc"], label="Train acc")
plt.plot(epochs, history["val_acc"], label="Val acc")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.title("ResNet18 – Accuracy")

curves_path = os.path.join(RESULTS_DIR, "resnet18_training_curves.png")
plt.tight_layout()
plt.savefig(curves_path, dpi=300)
plt.show()
print(f"Графики обучения сохранены в: {curves_path}")

resnet18.eval()
all_labels = []
all_preds = []

with torch.no_grad():
    for inputs, labels in tqdm(final_test_loader, desc="Final test"):
        inputs = inputs.to(device)
        labels = labels.to(device)

        outputs = resnet18(inputs)
        _, preds = torch.max(outputs, 1)

        all_labels.extend(labels.cpu().numpy())
        all_preds.extend(preds.cpu().numpy())

all_labels = np.array(all_labels)
all_preds = np.array(all_preds)

test_acc = (all_labels == all_preds).mean()
print(f"\nFinal test accuracy (ProcessedTest): {test_acc:.4f}")

class_labels_ordered = [idx_to_class[i] for i in range(num_classes)]

report = classification_report(
    all_labels,
    all_preds,
    target_names=class_labels_ordered,
    digits=4
)
print("\nClassification report (ProcessedTest):")
print(report)

report_path = os.path.join(RESULTS_DIR, "resnet18_classification_report.txt")
with open(report_path, "w") as f:
    f.write(f"Final test accuracy: {test_acc:.4f}\n\n")
    f.write(report)
print(f"Отчёт по метрикам сохранён в: {report_path}")
и
cm = confusion_matrix(all_labels, all_preds)

plt.figure(figsize=(12, 10))
sns.heatmap(
    cm,
    annot=False,
    fmt="d",
    cmap="Blues",
    xticklabels=class_labels_ordered,
    yticklabels=class_labels_ordered
)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("ResNet18 – Confusion Matrix (ProcessedTest)")
cm_path = os.path.join(RESULTS_DIR, "resnet18_confusion_matrix.png")
plt.tight_layout()
plt.savefig(cm_path, dpi=300)
plt.show()
print(f"Confusion matrix сохранена в: {cm_path}")